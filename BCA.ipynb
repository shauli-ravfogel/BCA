{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import scipy\n",
    "from scipy import linalg\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "import tqdm\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"encodings.bert-base.250k.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100000, 768]), torch.Size([768, 30522]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = np.array([d[\"vec_batch_norm\"] for d in data])\n",
    "with open(\"bert_embeddings.pickle\", \"rb\") as f:\n",
    "    W = pickle.load(f)\n",
    "    \n",
    "H,W = torch.from_numpy(H).double(), torch.from_numpy(W).double()\n",
    "H = H[:100000]\n",
    "W = W.T\n",
    "H.shape, W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5134, 0.5406, 0.4952,  ..., 0.4864, 0.3009, 0.5797])\n"
     ]
    }
   ],
   "source": [
    "# N = 100000\n",
    "# d = 128\n",
    "# l = 25\n",
    "# H = (torch.randn(N,d) + torch.rand(N,d)**2)\n",
    "\n",
    "# H = H - torch.mean(H, dim = 0, keepdim = True)\n",
    "# H = H\n",
    "# W = torch.randn(d,l)\n",
    "cov_H = torch.tensor(np.cov(H.detach().cpu().numpy(), rowvar = False))\n",
    "print(cov_H[0]@W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# start = time.time()\n",
    "# Q = cov_H[:1000]@W\n",
    "# print(Q)\n",
    "# print(cov_H.shape, W.shape)\n",
    "# print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u = torch.nn.Parameter(u)\n",
    "# optimizer = torch.optim.SGD([u], lr=0.001, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cov_output_projected(u, cov_H, W):\n",
    "    \n",
    "    u_normed = u / torch.norm(u)\n",
    "    P = torch.eye(cov_H.shape[0]) - (u_normed@u_normed.T)\n",
    "    #P = u_normed@u_normed.T\n",
    "    print(P.shape, W.shape, cov_H.shape, u_normed.shape)\n",
    "    first = P@W\n",
    "    print(\"done first\")\n",
    "    second = cov_H@first\n",
    "    print(\"done second\")\n",
    "    third = P@second\n",
    "    print(\"done third\")\n",
    "    fourth = W.T@third\n",
    "    print(\"done fourth\")\n",
    "    return fourth\n",
    "    #return W.T@P@cov_H@P@W\n",
    "\n",
    "def get_cov_output_total(H,W,n=10000):\n",
    "    with torch.no_grad():\n",
    "        Y_hat = H[:n]@W \n",
    "        Y_hat = Y_hat - torch.mean(Y_hat, dim = 1, keepdim = True)\n",
    "        return torch.sum(Y_hat*Y_hat)/Y_hat.shape[0]\n",
    "    #return torch.tensor(np.cov(Y_hat.detach().cpu().numpy(), rowvar = False))\n",
    "\n",
    "def eval_total_var(H,W):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        k = 2000\n",
    "        Y_sum = torch.zeros(W.shape[1])\n",
    "        Y_sqr_sum = torch.zeros(W.shape[1])\n",
    "    \n",
    "        for i in range(0,len(H), k):\n",
    "            Y = H[i:i+k]@W\n",
    "            Y_sum += torch.sum(Y, dim = 0)\n",
    "            Y_sqr_sum += torch.sum(Y**2, dim = 0)\n",
    "    \n",
    "        Y_sqr_sum /= len(H)\n",
    "        Y_sum /= len(H)\n",
    "        return (Y_sqr_sum - Y_sum**2).mean() # mean over vocab\n",
    "    \n",
    "def get_loss_func(cov_output_projected):\n",
    "    \n",
    "    loss =  torch.sum(torch.diag(cov_output_projected))\n",
    "    print(\"done loss calculation\")\n",
    "    return loss\n",
    "\n",
    "def get_loss_func2(u, cov_H, W):\n",
    "\n",
    "    u_normed = u / torch.norm(u)\n",
    "    P = torch.eye(cov_H.shape[0]) - (u_normed@u_normed.T)\n",
    "    #P = u_normed@u_normed.T\n",
    "    first = P@W\n",
    "    second = cov_H@first\n",
    "    third = P@second\n",
    "    fourth = torch.sum(W*third)/third.shape[1] # mean over vocab\n",
    "    return fourth \n",
    "\n",
    "def get_projection_to_intersection_of_nullspaces(rowspace_projection_matrices: List[np.ndarray], input_dim: int):\n",
    "    \"\"\"\n",
    "    Given a list of rowspace projection matrices P_R(w_1), ..., P_R(w_n),\n",
    "    this function calculates the projection to the intersection of all nullspasces of the matrices w_1, ..., w_n.\n",
    "    uses the intersection-projection formula of Ben-Israel 2013 http://benisrael.net/BEN-ISRAEL-NOV-30-13.pdf:\n",
    "    N(w1)∩ N(w2) ∩ ... ∩ N(wn) = N(P_R(w1) + P_R(w2) + ... + P_R(wn))\n",
    "    :param rowspace_projection_matrices: List[np.array], a list of rowspace projections\n",
    "    :param dim: input dim\n",
    "    \"\"\"\n",
    "\n",
    "    I = np.eye(input_dim)\n",
    "    Q = np.sum(rowspace_projection_matrices, axis = 0)\n",
    "    P = I - get_rowspace_projection(Q)\n",
    "\n",
    "    return P\n",
    "\n",
    "def get_rowspace_projection(W: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    :param W: the matrix over its nullspace to project\n",
    "    :return: the projection matrix over the rowspace\n",
    "    \"\"\"\n",
    "\n",
    "    if np.allclose(W, 0):\n",
    "        w_basis = np.zeros_like(W.T)\n",
    "    else:\n",
    "        w_basis = scipy.linalg.orth(W.T) # orthogonal basis\n",
    "\n",
    "    P_W = w_basis.dot(w_basis.T) # orthogonal projection on W's rowspace\n",
    "\n",
    "    return P_W\n",
    "\n",
    "def get_first_pca(H):\n",
    "    pca = PCA(n_components = 1)\n",
    "    pca.fit(H)\n",
    "    return torch.from_numpy(pca.components_.T)\n",
    "\n",
    "def BCA(H,W,n_components, eps = 1e-8, max_iters = 1000, init_pca = True):\n",
    "    \n",
    "    P_nullspace = torch.eye(H.shape[1])\n",
    "    results = []\n",
    "    #cov_out_total = get_cov_output_total(H,W)\n",
    "    total_var_orig = eval_total_var(H,W) #get_loss_func(cov_out_total).detach().cpu().numpy().item()\n",
    "    remaining_var = total_var_orig\n",
    "    print(\"Total var original: \", remaining_var)\n",
    "    H_proj = H.clone()\n",
    "    rowspace_projs = []\n",
    "    \n",
    "    for i in range(n_components):\n",
    "        \n",
    "        H_proj = H@P_nullspace # remove previous component \n",
    "        cov_H = torch.from_numpy(np.cov(H_proj.detach().cpu().numpy(), rowvar = False))\n",
    "        \n",
    "        if init_pca:\n",
    "            u = get_first_pca(H_proj.detach().cpu().numpy())\n",
    "        else:\n",
    "            u = torch.randn(H_proj.shape[1], 1)\n",
    "        u = torch.nn.Parameter(u)\n",
    "        optimizer = torch.optim.SGD([u], lr=1e-3, momentum=0.6)\n",
    "        #optimizer = torch.optim.Adam([u], weight_decay = 1e-5)\n",
    "        \n",
    "        diff = 10\n",
    "        j = 0\n",
    "        loss_vals = [np.inf]\n",
    "        patience = 4\n",
    "        patience_counter = 0\n",
    "        \n",
    "        while j < max_iters and patience_counter < patience:\n",
    "            optimizer.zero_grad()\n",
    "            #cov_out = get_cov_output_projected(u,cov_H,W)\n",
    "            #loss = get_loss_func(cov_out)\n",
    "            loss = get_loss_func2(u, cov_H, W)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_vals.append(loss.detach().cpu().numpy().item())\n",
    "            diff = np.abs(loss_vals[-1] - loss_vals[-2])\n",
    "            \n",
    "            if diff > eps:\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            if j % 1 == 0: print(\"j, loss, \", j, loss.detach().cpu().numpy().item(), diff)\n",
    "            j += 1\n",
    "        print(\"finished after {} iters\".format(j))\n",
    "        \n",
    "        # calculate new nullspace projection to neutralzie component u\n",
    "        \n",
    "        u_normed = u / torch.norm(u)\n",
    "        rowspace_projs.append((u_normed@u_normed.T).detach().cpu().numpy())\n",
    "        P_nullspace = torch.from_numpy(get_projection_to_intersection_of_nullspaces(rowspace_projs,cov_H.shape[0]))\n",
    "        #P_nullspace = torch.eye(H_proj.shape[1]).double() - u_normed@u_normed.T\n",
    "        \n",
    "        # calcualte explained variance\n",
    "        #cov_out_total = get_cov_output_total(H,W)\n",
    "        total_var = eval_total_var(H,W)\n",
    "        #cov_out_projected = get_cov_output_projected(u,cov_H,W)\n",
    "        #total_var_projected = get_loss_func(cov_out_projected).detach().cpu().numpy().item()\n",
    "        total_var_projected = remaining_var - get_loss_func2(u,cov_H,W)\n",
    "        explained_var = total_var_projected / total_var\n",
    "        remaining_var = remaining_var - total_var_projected\n",
    "        \n",
    "        u = u / u.norm()\n",
    "        results.append({\"vec\": u.squeeze().detach().cpu().numpy(), \"projected_var\": total_var_projected,\n",
    "                       \"total_var\": total_var, \"explained_var\": total_var_projected*100})\n",
    "    \n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bca = BCA(H,W,n_components=3, eps = 1e-5, init_pca = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bca[0][\"vec\"].T@bca[3][\"vec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0.0005941315742366976\n",
      "0 2 -0.00346429962490186\n",
      "1 2 -0.0009767608591731165\n"
     ]
    }
   ],
   "source": [
    "vecs = np.array([x[\"vec\"] for x in bca])\n",
    "for i,v in enumerate(vecs):\n",
    "    for j, v2 in enumerate(vecs):\n",
    "        if j <= i: continue\n",
    "            \n",
    "        print(i,j, v@v2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.3799162134893"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(bca[0][\"vec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for i in range(len(bca)):\n",
    "    \n",
    "    #print(bca[i][\"explained_var\"])\n",
    "    \n",
    "cov_out_total = get_cov_output_total(H,W)\n",
    "total_var = get_loss_func(cov_out_total).detach().cpu().numpy().item()    \n",
    "vars = [x[\"explained_var\"] for x in bca]\n",
    "print(vars)\n",
    "print(sum(vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bca[-1][\"cov_out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bca[-3][\"explained_var\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,v = np.random.randn(768), np.random.randn(768).T\n",
    "u,v = u / np.linalg.norm(u), v/np.linalg.norm(v)\n",
    "u@v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5,6,7,8,9,10,11,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[-12:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.rand(768,32000)\n",
    "H = np.random.rand(10000,768)\n",
    "H*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn(768,32000)\n",
    "H = torch.randn(10000, 768)\n",
    "Y_hat = H[:10000]@W \n",
    "torch.mean(Y_hat*Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100000, 768]), torch.Size([768, 30522]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape, W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_first_comp = get_first_pca(H)\n",
    "Y = H[:10000]@W\n",
    "Y_first_comp = get_first_pca(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.4340, 4.4635, 4.4105,  ..., 3.8644, 3.4939, 4.9670])\n"
     ]
    }
   ],
   "source": [
    "total_var = eval_total_var(H,W)\n",
    "print(total_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.6453)\n"
     ]
    }
   ],
   "source": [
    "print(total_var.sum()/W.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.1035)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.randn(768,1)\n",
    "get_loss_func2(H_first_comp, cov_H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5%1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
