{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import scipy\n",
    "from scipy import linalg\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "import tqdm\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"encodings.bert-base.250k.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "sents = np.array([d[\"sent\"] for d in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = np.array(sents)\n",
    "masked_tokens = np.array([d[\"gold\"] for d in data])\n",
    "top_words = np.array([d[\"top_words\"][0] for d in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Game ) is a 2003 Bollywood Action film directed by Yusuf Khan .\n",
      "is\n",
      "is\n"
     ]
    }
   ],
   "source": [
    "print(sents[2])\n",
    "print(masked_tokens[2])\n",
    "print(top_words[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100000, 768]), torch.Size([768, 30522]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = np.array([d[\"vec_batch_norm\"] for d in data])\n",
    "with open(\"bert_embeddings.pickle\", \"rb\") as f:\n",
    "    W = pickle.load(f)\n",
    "    \n",
    "H,W = torch.from_numpy(H).double(), torch.from_numpy(W).double()\n",
    "H = H[:100000]\n",
    "W = W.T\n",
    "H.shape, W.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5134, 0.5406, 0.4952,  ..., 0.4864, 0.3009, 0.5797])\n"
     ]
    }
   ],
   "source": [
    "# N = 100000\n",
    "# d = 128\n",
    "# l = 25\n",
    "# H = (torch.randn(N,d) + torch.rand(N,d)**2)\n",
    "\n",
    "# H = H - torch.mean(H, dim = 0, keepdim = True)\n",
    "# H = H\n",
    "# W = torch.randn(d,l)\n",
    "cov_H = torch.tensor(np.cov(H.detach().cpu().numpy(), rowvar = False))\n",
    "print(cov_H[0]@W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# start = time.time()\n",
    "# Q = cov_H[:1000]@W\n",
    "# print(Q)\n",
    "# print(cov_H.shape, W.shape)\n",
    "# print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u = torch.nn.Parameter(u)\n",
    "# optimizer = torch.optim.SGD([u], lr=0.001, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cov_output_projected(u, cov_H, W):\n",
    "    \n",
    "    u_normed = u / torch.norm(u)\n",
    "    P = torch.eye(cov_H.shape[0]) - (u_normed@u_normed.T)\n",
    "    #P = u_normed@u_normed.T\n",
    "    print(P.shape, W.shape, cov_H.shape, u_normed.shape)\n",
    "    first = P@W\n",
    "    print(\"done first\")\n",
    "    second = cov_H@first\n",
    "    print(\"done second\")\n",
    "    third = P@second\n",
    "    print(\"done third\")\n",
    "    fourth = W.T@third\n",
    "    print(\"done fourth\")\n",
    "    return fourth\n",
    "    #return W.T@P@cov_H@P@W\n",
    "\n",
    "def get_cov_output_total(H,W,n=10000):\n",
    "    with torch.no_grad():\n",
    "        Y_hat = H[:n]@W \n",
    "        Y_hat = Y_hat - torch.mean(Y_hat, dim = 1, keepdim = True)\n",
    "        return torch.sum(Y_hat*Y_hat)/Y_hat.shape[0]\n",
    "    #return torch.tensor(np.cov(Y_hat.detach().cpu().numpy(), rowvar = False))\n",
    "\n",
    "def eval_total_var(H,W):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        k = 2000\n",
    "        Y_sum = torch.zeros(W.shape[1])\n",
    "        Y_sqr_sum = torch.zeros(W.shape[1])\n",
    "    \n",
    "        for i in range(0,len(H), k):\n",
    "            Y = H[i:i+k]@W\n",
    "            Y_sum += torch.sum(Y, dim = 0)\n",
    "            Y_sqr_sum += torch.sum(Y**2, dim = 0)\n",
    "    \n",
    "        Y_sqr_sum /= len(H)\n",
    "        Y_sum /= len(H)\n",
    "        return (Y_sqr_sum - Y_sum**2).mean() # mean over vocab\n",
    "    \n",
    "def get_loss_func(cov_output_projected):\n",
    "    \n",
    "    loss =  torch.sum(torch.diag(cov_output_projected))\n",
    "    print(\"done loss calculation\")\n",
    "    return loss\n",
    "\n",
    "def get_loss_func2(u, cov_H, W):\n",
    "\n",
    "    u_normed = u / torch.norm(u)\n",
    "    P = torch.eye(cov_H.shape[0]) - (u_normed@u_normed.T)\n",
    "    #P = u_normed@u_normed.T\n",
    "    first = P@W\n",
    "    second = cov_H@first\n",
    "    third = P@second\n",
    "    fourth = torch.sum(W*third)/third.shape[1] # mean over vocab\n",
    "    return fourth \n",
    "\n",
    "def get_projection_to_intersection_of_nullspaces(rowspace_projection_matrices: List[np.ndarray], input_dim: int):\n",
    "    \"\"\"\n",
    "    Given a list of rowspace projection matrices P_R(w_1), ..., P_R(w_n),\n",
    "    this function calculates the projection to the intersection of all nullspasces of the matrices w_1, ..., w_n.\n",
    "    uses the intersection-projection formula of Ben-Israel 2013 http://benisrael.net/BEN-ISRAEL-NOV-30-13.pdf:\n",
    "    N(w1)∩ N(w2) ∩ ... ∩ N(wn) = N(P_R(w1) + P_R(w2) + ... + P_R(wn))\n",
    "    :param rowspace_projection_matrices: List[np.array], a list of rowspace projections\n",
    "    :param dim: input dim\n",
    "    \"\"\"\n",
    "\n",
    "    I = np.eye(input_dim)\n",
    "    Q = np.sum(rowspace_projection_matrices, axis = 0)\n",
    "    P = I - get_rowspace_projection(Q)\n",
    "\n",
    "    return P\n",
    "\n",
    "def get_rowspace_projection(W: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    :param W: the matrix over its nullspace to project\n",
    "    :return: the projection matrix over the rowspace\n",
    "    \"\"\"\n",
    "\n",
    "    if np.allclose(W, 0):\n",
    "        w_basis = np.zeros_like(W.T)\n",
    "    else:\n",
    "        w_basis = scipy.linalg.orth(W.T) # orthogonal basis\n",
    "\n",
    "    P_W = w_basis.dot(w_basis.T) # orthogonal projection on W's rowspace\n",
    "\n",
    "    return P_W\n",
    "\n",
    "def get_first_pca(H):\n",
    "    pca = PCA(n_components = 1)\n",
    "    pca.fit(H)\n",
    "    return torch.from_numpy(pca.components_.T)\n",
    "\n",
    "def BCA(H,W,n_components, eps = 1e-8, max_iters = 1000, min_iters = 150, init_pca = True):\n",
    "    \n",
    "    P_nullspace = torch.eye(H.shape[1])\n",
    "    results = []\n",
    "    #cov_out_total = get_cov_output_total(H,W)\n",
    "    total_var_orig = eval_total_var(H,W) #get_loss_func(cov_out_total).detach().cpu().numpy().item()\n",
    "    remaining_var = total_var_orig\n",
    "    print(\"Total var original: \", remaining_var)\n",
    "    H_proj = H.clone()\n",
    "    rowspace_projs = []\n",
    "    \n",
    "    for i in range(n_components):\n",
    "        \n",
    "        H_proj = H@P_nullspace # remove previous component \n",
    "        cov_H = torch.from_numpy(np.cov(H_proj.detach().cpu().numpy(), rowvar = False))\n",
    "        \n",
    "        if init_pca:\n",
    "            u = get_first_pca(H_proj.detach().cpu().numpy())\n",
    "        else:\n",
    "            u = torch.randn(H_proj.shape[1], 1)\n",
    "        u = torch.nn.Parameter(u)\n",
    "        optimizer = torch.optim.SGD([u], lr=3*1e-2, momentum=0.25)\n",
    "        #optimizer = torch.optim.Adam([u])\n",
    "        \n",
    "        diff = 10\n",
    "        j = 0\n",
    "        loss_vals = [np.inf]\n",
    "        patience = 10\n",
    "        patience_counter = 0\n",
    "        \n",
    "        while j < max_iters and patience_counter < patience:\n",
    "            optimizer.zero_grad()\n",
    "            #cov_out = get_cov_output_projected(u,cov_H,W)\n",
    "            #loss = get_loss_func(cov_out)\n",
    "            loss = get_loss_func2(u, cov_H, W)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_vals.append(loss.detach().cpu().numpy().item())\n",
    "            diff = np.abs(loss_vals[-1] - loss_vals[-2])\n",
    "            \n",
    "            if diff > eps:\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                if j > min_iters:\n",
    "                    patience_counter += 1\n",
    "                \n",
    "            if j % 25 == 0: print(\"j, loss, \", j, loss.detach().cpu().numpy().item(), diff)\n",
    "            j += 1\n",
    "        print(\"finished after {} iters\".format(j))\n",
    "        \n",
    "        # calculate new nullspace projection to neutralzie component u\n",
    "        \n",
    "        u_normed = u / torch.norm(u)\n",
    "        rowspace_projs.append((u_normed@u_normed.T).detach().cpu().numpy())\n",
    "        P_nullspace = torch.from_numpy(get_projection_to_intersection_of_nullspaces(rowspace_projs,cov_H.shape[0]))\n",
    "        #P_nullspace = torch.eye(H_proj.shape[1]).double() - u_normed@u_normed.T\n",
    "        \n",
    "        # calcualte explained variance\n",
    "        #cov_out_total = get_cov_output_total(H,W)\n",
    "        total_var = eval_total_var(H,W)\n",
    "        #cov_out_projected = get_cov_output_projected(u,cov_H,W)\n",
    "        #total_var_projected = get_loss_func(cov_out_projected).detach().cpu().numpy().item()\n",
    "        total_var_projected = remaining_var - get_loss_func2(u,cov_H,W)\n",
    "        explained_var = total_var_projected / total_var_orig\n",
    "        remaining_var = remaining_var - total_var_projected\n",
    "        \n",
    "        u = u / u.norm()\n",
    "        results.append({\"vec\": u.squeeze().detach().cpu().numpy(), \"projected_var\": total_var_projected,\n",
    "                       \"total_var\": total_var, \"explained_var\": total_var_projected*100})\n",
    "    \n",
    "    return results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total var original:  tensor(5.6453)\n",
      "j, loss,  0 5.103504540583716 inf\n",
      "j, loss,  25 4.563359069997909 0.01486304000367511\n",
      "j, loss,  50 4.263849139912718 0.00902478341531232\n",
      "j, loss,  75 4.100062379082116 0.004877269240622262\n",
      "j, loss,  100 4.000624601050575 0.003356657719244538\n",
      "j, loss,  125 3.92816104533149 0.002518444157333377\n",
      "j, loss,  150 3.874233945310986 0.0018436812287796478\n",
      "j, loss,  175 3.835143196388439 0.0013372826777038327\n",
      "j, loss,  200 3.8062502824568307 0.0010118175164461896\n",
      "j, loss,  225 3.783904661746057 0.0007975775978374955\n",
      "j, loss,  250 3.766061339880651 0.0006434790743754526\n",
      "j, loss,  275 3.7515728028505038 0.0005250326030097341\n",
      "j, loss,  300 3.7397207665125043 0.0004302122285397836\n",
      "j, loss,  325 3.730005061917473 0.00035265956841534774\n",
      "j, loss,  350 3.722045472807963 0.00028870560646998555\n",
      "j, loss,  375 3.715534494587027 0.0002359969256486849\n",
      "j, loss,  400 3.7102141629080663 0.00019281820038541397\n",
      "j, loss,  425 3.7058651931832403 0.00015773935132479266\n",
      "j, loss,  450 3.702302165570132 0.00012946317379736172\n",
      "j, loss,  475 3.69937076711459 0.0001067953547608802\n"
     ]
    }
   ],
   "source": [
    "bca = BCA(H,W,n_components=3, eps = 0.5*1e-4, init_pca = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bca[0][\"vec\"].T@bca[3][\"vec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0.00011314179064859584\n",
      "0 2 -0.00017821977203982126\n",
      "1 2 0.0002278588081749272\n"
     ]
    }
   ],
   "source": [
    "vecs = np.array([x[\"vec\"] for x in bca])\n",
    "for i,v in enumerate(vecs):\n",
    "    for j, v2 in enumerate(vecs):\n",
    "        if j <= i: continue\n",
    "            \n",
    "        print(i,j, v@v2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(bca[0][\"vec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1.9592, grad_fn=<SubBackward0>), tensor(0.1169, grad_fn=<SubBackward0>), tensor(0.1146, grad_fn=<SubBackward0>)]\n",
      "tensor(2.1907, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#for i in range(len(bca)):\n",
    "    \n",
    "    #print(bca[i][\"explained_var\"])\n",
    "    \n",
    "#cov_out_total = get_cov_output_total(H,W)\n",
    "#total_var = get_loss_func(cov_out_total).detach().cpu().numpy().item()    \n",
    "vars = [x[\"projected_var\"] for x in bca]\n",
    "print(vars)\n",
    "print(sum(vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",  --------  The municipality of Berra contains the frazioni ( subdivisions , mainly villages and hamlets ) Cologna and Serravalle . --------- -5.448562479435196\n",
      "======================================\n",
      "Be'er  --------  Located near Kiryat Malakhi with 98 farms covering an area of 6 , 000 dunams , it falls under the jurisdiction of Be'er Tuvia Regional Council . --------- -4.6270222685213325\n",
      "======================================\n",
      ",  --------  Hamma is a village and a former municipality in the Eichsfeld district , in Thuringia , Germany . --------- -4.401286464200628\n",
      "======================================\n",
      ",  --------  Nochern is a municipality and village in the district of Rhein-Lahn , in Rhineland-Palatinate , in western Germany . --------- -4.29506809569322\n",
      "======================================\n",
      "the  --------  At the time of NRHP listing it was owned by Kennecott Copper Corporation . --------- -4.256045699116503\n",
      "======================================\n",
      "in  --------  As a designated place in the 2011 Census , Sunset Acres had a population of 61 living in 22 of its 22 total dwellings , a -3 . --------- -4.186547405002317\n",
      "======================================\n",
      "by  --------  Homeobox protein DLX-5 is a protein that in humans is encoded by the DLX5 gene . --------- -4.115912405871576\n",
      "======================================\n",
      ",  --------  The baseball team won the 2002 North I , Group II state sectional championship , defeating Hoboken High School 4-3 in the tournament final . --------- -3.888736165254679\n",
      "======================================\n",
      ",  --------  Lorain Township is a township in Nobles County , Minnesota , United States . --------- -3.8860582947775644\n",
      "======================================\n",
      "of  --------  Hasbrouck Heights is governed under the Borough form of New Jersey municipal government . --------- -3.6069458833366324\n",
      "======================================\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "石恢  --------  Shi Hui ( 石恢 ) , the Prince of Nanyang ( 330 , executed by Shi Hu 334 ) .\n",
      "======================================\n",
      "301  --------  As of the census of 2000 , there were 1 , 301 people , 485 households , and 358 families residing in the town .\n",
      "======================================\n",
      "267  --------  As of the 2010 census , its population was 585 and it contained 267 housing units .\n",
      "======================================\n",
      "214  --------  As of the 2010 census , its population was 2 , 894 and it contained 1 , 214 housing units .\n",
      "======================================\n",
      "222  --------  The population was 1 , 222 at the 2000 census , and 1 , 167 at a 2009 estimate .\n",
      "======================================\n",
      "305  --------  As per 2001 census , Sonamukhi block had a total population of 142 , 305 , out of which 73 , 200 were males and 69 , 105 were females .\n",
      "======================================\n",
      "930  --------  As of the census of 2000 , there were 25 , 440 people , 8 , 102 households , and 5 , 930 families residing in the parish .\n",
      "======================================\n",
      "231  --------  There were 3 , 231 housing units at an average density of 1 , 158 .\n",
      "======================================\n",
      "Fesca  --------  Alexander Ernst Fesca ( 22 May 1820 in Karlsruhe , 22 February 1849 in Braunschweig ) was a German composer and pianist .\n",
      "======================================\n",
      "裙  --------  It consists of a blouse ( 襦 , ru ) and a wrap-around skirt ( 裙 , qun ) .\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "u = bca[0][\"vec\"]\n",
    "#u = np.expand_dims(u, axis=1)\n",
    "vecs = H.detach().cpu().numpy()\n",
    "vecs_u = vecs@u\n",
    "idx = np.argsort(vecs_u)\n",
    "k = 50\n",
    "top_neg, top_pos = idx[:k], idx[-k:]\n",
    "\n",
    "sents_pos = sents[top_pos]\n",
    "sents_neg = sents[top_neg]\n",
    "gold_pos = masked_tokens[top_pos]\n",
    "gold_neg = masked_tokens[top_neg]\n",
    "preds_pos = top_words[top_pos]\n",
    "preds_neg = top_words[top_neg]\n",
    "\n",
    "for i in range(10):\n",
    "    print(gold_pos[i], \" -------- \", sents_pos[i], \"---------\", vecs_u[idx[i]])\n",
    "    print(\"======================================\")\n",
    "    \n",
    "print(\"&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\")\n",
    "\n",
    "for i in range(10):\n",
    "    print(gold_neg[i], \" -------- \", sents_neg[i])\n",
    "    print(\"======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bca[-1][\"cov_out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bca[-3][\"explained_var\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,v = np.random.randn(768), np.random.randn(768).T\n",
    "u,v = u / np.linalg.norm(u), v/np.linalg.norm(v)\n",
    "u@v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5,6,7,8,9,10,11,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[-12:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.rand(768,32000)\n",
    "H = np.random.rand(10000,768)\n",
    "H*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn(768,32000)\n",
    "H = torch.randn(10000, 768)\n",
    "Y_hat = H[:10000]@W \n",
    "torch.mean(Y_hat*Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100000, 768]), torch.Size([768, 30522]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape, W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_first_comp = get_first_pca(H)\n",
    "Y = H[:10000]@W\n",
    "Y_first_comp = get_first_pca(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.4340, 4.4635, 4.4105,  ..., 3.8644, 3.4939, 4.9670])\n"
     ]
    }
   ],
   "source": [
    "total_var = eval_total_var(H,W)\n",
    "print(total_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.6453)\n"
     ]
    }
   ],
   "source": [
    "print(total_var.sum()/W.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.1035)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.randn(768,1)\n",
    "get_loss_func2(H_first_comp, cov_H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5%1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
