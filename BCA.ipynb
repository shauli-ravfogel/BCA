{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "d = 32\n",
    "l = 64\n",
    "H = torch.randn(N,d) + torch.rand(N,d)**2\n",
    "\n",
    "H = H - torch.mean(H, dim = 0, keepdim = True)\n",
    "W = torch.randn(d,l)\n",
    "cov_H = torch.tensor(np.cov(H.detach().cpu().numpy(), rowvar = False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.randn(d,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.nn.Parameter(u)\n",
    "optimizer = torch.optim.SGD([u], lr=0.001, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cov_output_projected(u, cov_H, W, project = True):\n",
    "    \n",
    "    u_normed = u / torch.norm(u)\n",
    "    if project:\n",
    "        P = u_normed@u_normed.T\n",
    "    else:\n",
    "        P = torch.eye(cov_H.shape[0])\n",
    "    return W.T@P@cov_H@P@W\n",
    "\n",
    "def get_loss_func(cov_output_projected):\n",
    "    \n",
    "    return -torch.sum(torch.diag(cov_output_projected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-56.2016, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_out = get_cov_output_projected(u.float(),cov_H.float(),W.float())\n",
    "get_loss_func(cov_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6231,  1.2822,  1.8030,  ...,  1.1869, -0.3423,  1.0715],\n",
       "        [ 1.2822,  1.0129,  1.4243,  ...,  0.9376, -0.2704,  0.8464],\n",
       "        [ 1.8030,  1.4243,  2.0028,  ...,  1.3185, -0.3802,  1.1902],\n",
       "        ...,\n",
       "        [ 1.1869,  0.9376,  1.3185,  ...,  0.8680, -0.2503,  0.7835],\n",
       "        [-0.3423, -0.2704, -0.3802,  ..., -0.2503,  0.0722, -0.2260],\n",
       "        [ 1.0715,  0.8464,  1.1902,  ...,  0.7835, -0.2260,  0.7073]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6231,  1.2822,  1.8030,  ...,  1.1869, -0.3423,  1.0715],\n",
       "        [ 1.2822,  1.0129,  1.4243,  ...,  0.9376, -0.2704,  0.8464],\n",
       "        [ 1.8030,  1.4243,  2.0028,  ...,  1.3185, -0.3802,  1.1902],\n",
       "        ...,\n",
       "        [ 1.1869,  0.9376,  1.3185,  ...,  0.8680, -0.2503,  0.7835],\n",
       "        [-0.3423, -0.2704, -0.3802,  ..., -0.2503,  0.0722, -0.2260],\n",
       "        [ 1.0715,  0.8464,  1.1902,  ...,  0.7835, -0.2260,  0.7073]])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_normed = u / torch.norm(u)\n",
    "P = u_normed@u_normed.T\n",
    "Y = H@P@W\n",
    "torch.Tensor(np.cov(Y.detach().cpu().numpy(), rowvar=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-63.87030029296875\n",
      "-186.16481018066406\n",
      "-188.79730224609375\n",
      "-189.3166046142578\n",
      "-189.4493865966797\n",
      "-189.48304748535156\n",
      "-189.4915771484375\n",
      "-189.49371337890625\n",
      "-189.4941864013672\n",
      "-189.4943389892578\n",
      "-189.49447631835938\n",
      "-189.4944305419922\n",
      "-189.49436950683594\n",
      "-189.49447631835938\n",
      "-189.49444580078125\n",
      "-189.49435424804688\n",
      "-189.49449157714844\n",
      "-189.49436950683594\n",
      "-189.49432373046875\n",
      "-189.494384765625\n"
     ]
    }
   ],
   "source": [
    "for i in range(800):\n",
    "    optimizer.zero_grad()\n",
    "    cov_out = get_cov_output_projected(u,cov_H.float(),W)\n",
    "    loss = get_loss_func(cov_out)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        print(loss.detach().cpu().numpy().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2677, -0.0253, -0.0333, -0.1426,  0.4683,  0.4370, -0.0010, -0.2550,\n",
       "         0.3309,  0.0120, -0.0158,  0.3556,  0.0782,  0.1854, -0.2046,  0.3055,\n",
       "         0.0177, -0.0521,  0.3623, -0.0094, -0.3348,  0.4240,  0.2525, -0.3816,\n",
       "         0.1589, -0.4915,  0.0954, -0.0662, -0.4441, -0.0526,  0.0868, -0.6774,\n",
       "        -0.3135,  0.0286,  0.1081,  0.3443, -0.0087, -0.2987, -0.2919, -0.2000,\n",
       "         0.3860, -0.1248, -0.2338,  0.2126,  0.1587, -0.2507,  0.3060,  0.3181,\n",
       "         0.0126, -0.6031,  0.0423, -0.1774,  0.0869,  0.3745, -0.0361, -0.2441,\n",
       "         0.1190,  0.4289, -0.2458, -0.2765,  0.1691,  0.0349, -0.0205,  0.1098],\n",
       "       grad_fn=<MvBackward>)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = u / torch.norm(u)\n",
    "WT = W.T/torch.norm(W.T, dim = 1, keepdim = True)\n",
    "WT@u.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance in output: 8.756929397583008%\n"
     ]
    }
   ],
   "source": [
    "cov_out_total = get_cov_output_projected(u,cov_H.float(),W, project = False)\n",
    "total_var = total_var_projected = -get_loss_func(cov_out_total)\n",
    "cov_out_projected = get_cov_output_projected(u,cov_H.float(),W, project = True)\n",
    "total_var_projected = -get_loss_func(cov_out_projected)\n",
    "explained_var = total_var_projected / total_var\n",
    "print(\"Explained variance in output: {}%\".format(explained_var*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
